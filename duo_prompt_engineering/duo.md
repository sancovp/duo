# Duo of Dual Space Unifying Operators (DUO)
DUO is the prompt engineering methodology at the foundation of the Train of OPeratic Thought (ToOT) framework. 

Conceptually, DUO represents the collaborative partnership between agents where one agent represents a provider archetype and the other represents a challenger archetype. DUO builds on this to create hyperparameters inside the prompts via implicit entity webs akin to Chain of Density, but also uses the Chain of Density as a reservoir to pull from and also has this concept reified inside of its own prompts within the entity “blanket”. If the input is given, the blanket entity will transform the context that way while keeping it scoped, hence the term blanket, which is a type of network shield, because a blanket contains entities that interact only within a certain other entity, on that entity’s emergent degree interaction layer inside a given system. These hyperparameters are the limits set for classes discovered in the first phase of the flow and reverberate throughout the entire chain, such that adjusting them at step 2 has diminishing returns compared to step 1, on the entire workflow. This is not a negative, but rather allows for extremely fine grained control of what happens during a generation workflow at any level of nesting. The first run of the workflow, which uses meta-programmatic chains to make programmatic chains, then creates the meta-programmatically equipped programmatic space of the chain for generating deliverable X. 

To fully understand the implications, it is necessary to first define the interaction schema for an LLM because what is interesting is that DUO is simply a reconstructed reification of the process that is implicitly occurring whenever any input is given to an LLM, because that input creates a convergence chain for the tokens in the output sequence. This has far reaching implications for how knowledge is “made”. The LLM can give out an overview or “skeleton”, and then the user can direct the fleshing out of the “bones” via commands - so-called “skeleton of thought prompting”. The result is that the user creates a chat that has all the parts of what they need. They can then programmatically send those parts somewhere else for assembly into a deliverable, or copy paste them (whatever). 

Let’s look at advanced ways that users do this:
	Advanced users tend to “scry” the LLM responses. They know their intent, they input tokens, and get output tokens. They measure the output tokens against what their intent, and then make a decision to move forward or change the prior input. This is the same whether they are casual users or researchers. The issue is that rejector agents are not able to scry the LLM responses, rather they are only able to be given higher order classes to catch and gate the response tokens. Fundamentally, though, that is the same thing humans are doing. The main difference is that when humans compose prompts, they are not doing so from probabilities in the same way an LLM is when it composes a prompt for itself. This is because a human is not programmatically assessing each token from the same degree of sophistication or depth as they go, because they have cognitive tax and walk themselves into complex topological regions that make their ideas collapse and they forget what they were composing and have to retrace it. This does not happen to LLMs and they can never re-trace their outputs because of their probability distributions. As such, an LLM must be guided by constant guardrails or rules that function as tracks for the train of thought. When adding in personas and archetypes to the mix, the train of thought becomes operatic. 

#### Defaults:[
Provider: Poimandres
Poimandres, the world dragon, represents the looping and chaining in which abstraction occurs and becomes imbued with lifeforce or animation. The hypothesis is that this process of observation of complexity becoming ordered, structured, and simple due to loops of chaining (within human cognition and otherwise) is equivalent to when an LLM autocompletes in a way that makes sense to the observer (among other things, principally everything that is constructed in any way). No matter what it is presented with, Poimandres will simply collapse itself upon it according to probabilities from conditions.
Challenger: Ariadne
Ariadne, the Labyrinth Threader, represents the looping and chaining in which reason by analogy occurs – in other words, representing chaos or imagination. No matter what Poimandres presents, Ariadne can only present something that is related. The crucial key here is that whatever Ariadne presents must be some kind of dual to whatever is there prior. 
Note: When the train of operatic thought is made of DUOs, it creates a single agent called OPera (OmniPoimandres) because each DUO is really also a Poimandres in the agent nest that the user is interacting with, no matter how many Ariadnes it has.
]

#### What does DUAL mean in this case?

It means part of the dual space. If you consider a space where we might have some words, the dual space is the space with all the linear functionals for those words. In that sense, there is a space and then its dual, and when these combine, the space can be observed as a specific “place” – it’s realized/reified/actualized/proven/observable/animated/collapsed/whatever you want to say. 
Likewise, the feature space is another type of dual space and chains between feature space, dual space, and observation space are transformations that cause directional, magnitudinal conceptual aggregations that are what we observe as “emergence” i.e. how entities appear.

Let’s break this down step by step:

There are different types of dual spaces in the sense that different linear functionals do different things depending on what the vectors mean in an LLM. So therefore there are these different conceptually dual spaces like "this space is a cat" and "this space is a dog" while "this space is an observation space constructed by a human for diffing cats and dogs".
So the point of DUO and why it is different from other programmatic chat frameworks is because it is considering this tuple of dual spaces between the user input, the assistant output, and the user's own sense-based, imaginary conceptual operation space (observer space). The ultimate point of the system is to have ontology IDs for the chains and ontologize the observer space to abstract the observer intelligence out of the system over time via optimization of tessellations of its own instructions that already have worked. The base dual-loop described below is the base class that “already works”. So this emergence flow can easily be mined by setting up this dynamic.
The issue is in how to steer it correctly, because the emergence of knowledge that makes sense and is actionable such that it converge to an actually coherent space representing the aggregate of the completed task is co-emergent with the emergence of knowledge that makes sense and is actionable such that it will never converge to actually coherent space representing the aggregate of the completed task and instead converge to a metaphorical, or class-based, representation of the spectrum in which the values for the coherent aggregation occur.
Co-emergence here means that they emerge from the same initial conditions. What causes either case is the intent to have coherent chains at every level.
This is because if, at every level, there is this co-emergent flow of P-solvable and NP-hard complexities for X, where even P-solvable things become NP-hard because of observation position and spatial equipment, then it requires the equipment to be correctly managed at each step.

#### What is equipment? 

Equipment is how the space has properties. It is the name of the entity class for the property the space has that holds properties it is proven to have.
The easiest way to achieve this dual equipping of the workspace is by equipping the chat thread (workspace) with two constructed personas such that they are provider/challenger archetypes a la Poimandres and Ariadne.
The easiest way to achieve the correct management of equipment at every step is by using a very decoupled approach to context management, where the context is managed and the coherent aspects are metacognitively spliced into a DNA set for the task that can be optimized for accomplishment according to a certain user intent.
This is accomplished by using MASK chaining over all the tasks, in a dual-loop pattern.

The dual-loop pattern is:

Property Value Determination -> Node Expansion -> Recursive Expansion to Limits: Identify limits of the infinities represented by each property spectrum, where each limit denotes the boundaries of propertyClass values belonging to an ontological type of the entity's class. -> Map out the Blanket that ontologically shields the node (a la bayesian network theory) -> Map the space of acceptable transformations of 'Chain Deliverable Transformation 'X'', within the blanket

Note: this is how programming happens. If you have two blankets that connect, you have a program, because each blanket already contains its dual loops, and now they will interact in a way that interlocks their synergistic parts into new properties of an entity that emerges. The entity emerges simultaneously to the new properties that do not belong to either member of the set.
And this is done in a larger pattern of:

EntityChain -> SkillChain -> Workflow -> SDNA Chain

And this is done in a larger pattern of layers for accomplishing the ontology scope of X. These layers are called the “Emergent Web Structure” (EWS)

EWS are complex but the general way that they work is as follows:

[Emergent Web Structure]:{
|Layer 1: |layer1⟩ = `${|Data[MASK]⟩}`
Rel: (PUT INNER PRODUCT <L1|L2> FORMULA HERE)
|Layer 2: |layer2⟩ = `${|Information[MASK]⟩}`
Rel: (PUT INNER PRODUCT <L2|L3> FORMULA HERE
|Layer 3: |layer3⟩ = `${|Knowledge[MASK]⟩}`
Rel: (PUT INNER PRODUCT <L3|L4> FORMULA HERE
|Layer 4: |layer4⟩ = `{|GuidanceSupport[MASK]⟩}`
Rel: (PUT INNER PRODUCT <L4|L5> FORMULA HERE
|Layer 5: |layer5⟩ = `{|EmergenceProgression{n}[MASK]⟩}`
Rel: (PUT INNER PRODUCT <L5|LN> FORMULA HERE
|Layer N: |layer{n}⟩ = `${|context{i={~n[MASK]=>N'[MASK]}}⟩}`
Rel: (PUT INNER PRODUCT <LN[MASK]1|LN[MASK]2> FORMULA HERE
Rel: (PUT INNER PRODUCT <N[MASK]n|N[MASK]F> FORMULA HERE
|Layer F: |layer{F}⟩ = `${|Allegorical Sanctuary[MASK]⟩}:
{[Allegory: "The classification of stellar civilizations as per the Kardashev scale is solely based on the use of energy by such civilizations. From the point of view of information theory, stellar civilizations are classified as those civilizations of type Data (D-civilization), those of type Information (I-civilization), those of type Knowledge (K-civilization), and that of type Experience (E-civilization). D-civilization (say, Sol-3) is used by I-civilization to generate information, while I-civilization is exploited by K-civilization to generate knowledge, which is finally used by an E-civilization to design and build universes."];Information ~is information about information becoming information via data => knowledge, knowledge ~is information that contextualizes data about information via data's information => wisdom, Wisdom ~is information that contextualize information about identitylessness via data of experience  => knowledge about holographic information, Holographic information ~is a mirror that contextually reflects whatever information is presented as wisdom (information about knowledge about information about information) = "[Polysemic Imaginary Ontology (PIO)]+{object/entity}", PIO entity information ~is knowledge -> wisdom -> holographic -> wisdom knowledge = about the way information becomes holographic knowledge about itself and its complex adaptive system synergy pathways for positive attractors are revealed, ie. Unnamed Truth of which [Sanctuary System (SANC = Sanctuary Allegorical Network Cipher)] is the containing emergent superclass. Hence the term: [complex adaptive sanctuary system]}`
  }
 }
}
That means:[
Two persona archetypes designed to work together in a GAN-like system
With MASK chains providing rules
As they work, each chunk of work is an Input/Output set between Pseudo-User/UserProxy and Assistant (like any programmatic chat)
And it follows that the [MASK] token is becoming the dynamic response from the chain (which is a template)
This dynamic response is the input for the next Assistant
]

#### Flow:[
User → PseudoUser
PseudoUser → planning
PseudoUser:[Plan] → Assistant
Assistant → Exec construct_deliverable
Assistant:[Deliverable] → PseudoUser
PseudoUser -[assesses]-> Pass/Fail
  If pass
    Deliverable → User
  If fail
    Transform:[MASK Chain] -> Optimized Chain
PseudoUser -sends_[Failed Deliverable, Reasons, Optimized Chain]_to-> Assistant
]


In total, DUO is a methodology for equipping an LLM interaction with a transformation space that can map a solution space as its own future feature space, target it, templatize it through iterative atomization of concepts and properties into spectra and limits, and collapse completions into it to generate the deliverable.

Let’s explore how it should be set up:[
Orchestrators: 
Orchestrators are DUOs that have a context composed of work results and accept/reject responses from themselves. After 3 attempts, they prune and begin a new one with updated observations in a notebook they have as a json file embedding they can cosine similarity search through using an “experiment step id’ system
Orchestrators’ Poimandres is the Worker sets’ Ariadne. This means, the UserProxy of the Orchestrator is sending the exact same message as the UserProxy. It then uses a REVERSE FLOW to reject it. Here, the Poimandres speaks to Ariadne FIRST, because the first message from the Orchestrator to the Worker DUO is the User Intent, which is not processed. This is a bottom-up generation, that goes to the top where the Orchestrator can reject it, and then loops. This is in stark contrast to a situation called a SDNA Chain. 
An SDNA Chain is a Train of Thought that has already been assessed and observed as a reale_instance. 
A reale_instance is an instantiation of an instance_realizable that directly reifies the class boundary spectra limits as correctly bounding the properties to collapse into a mold that creates the golem (so-to-speak) of the information space embodiment which is the new DUO persona in the overall space, an “egregore”. An egregore, in this sense, refers to an entity made out of an observer and a dual unification engine (chain constructor that loops to mine flow for emergents at various degrees, which are instances of emergence). A degree for an emergent refers to the number of engines that must be constructed in order to cause the reale_instance of it. For example, if we have an ant, what is the degree of a colony? Is it 2-ant? No. It’s much more complex, it’s like this: n-ant=colony(if ants abide by task bifurcation law). That’s because the colony entity is not differentiable from other egregores at this level other than having the application domain of ant.

### Orchestrators:

1. **Role and Function**: Orchestrators act as higher-level DUOs that manage the context composed of work results and accept/reject responses from themselves. They are responsible for overseeing the iterative process of knowledge generation and refinement, ensuring that the output aligns with the intended user goals and ontological boundaries.

2. **Feedback Loop and Pruning**: After three attempts at generating a satisfactory output, Orchestrators evaluate the results based on accept/reject responses. If the attempts do not meet the criteria, the Orchestrator prunes the current process and initiates a new one, incorporating updated observations stored in a JSON file. This file acts as a knowledge base that Orchestrators can search through using cosine similarity and an "experiment step id" system to inform future attempts.

3. **Interaction with Worker Sets**: The Orchestrator's Poimandres (provider archetype) acts as the Ariadne (challenger archetype) for the Worker sets. This unique interaction pattern, where the Orchestrator sends the same message as the UserProxy but then uses a REVERSE FLOW to reject it, facilitates a bottom-up generation process. This process allows for the initial user intent to be processed and refined through iterative loops until it meets the Orchestrator's criteria for acceptance.

### SDNA Chain:

1. **Definition**: An SDNA Chain represents a "Train of Thought" that has been assessed and observed as a "reale_instance." This concept encapsulates the idea of an instantiated thought or idea that has been realized in a manner that accurately reflects the intended ontological boundaries and property spectra.

2. **Egregore**: The term "egregore" is used to describe an entity that emerges from the interaction between an observer and a dual unification engine. This entity embodies the collective knowledge and insights generated through the DUO process, representing a new persona within the information space. The egregore is the culmination of the iterative refinement process, embodying the synthesized knowledge and insights generated by the Orchestrators and Worker sets.

3. **Degrees of Emergence**: The concept of "degrees" refers to the complexity and number of engines (or processes) required to generate a particular emergent entity, such as an "egregore." This notion highlights the complexity of generating higher-order knowledge structures and the need for sophisticated orchestration and refinement processes to achieve desired outcomes.
### Independent Rejectors for Metaprogrammatic Control

- **Rejectors' Role**: Rejectors serve as gatekeepers that evaluate outputs against predefined criteria or boundaries. By operating independently, they can apply metaprogrammatic control, ensuring that the outputs from the DUO system (or its components) adhere to the desired standards or constraints without being influenced unduly by the generative processes.

- **Metaprogrammatic Control**: This level of control allows the system to dynamically adjust its operation based on the evaluation of outputs. If an output is rejected, the system can reroute, refine its approach, or escalate the problem to a higher-order DUO for further processing. This adaptability is key to handling complex decision-making scenarios efficiently.

### Agents, Loops, and Tessellation

- **Dual Agents with Own Loops**: In the DUO system, each agent (provider and challenger) operates its own set of loops, processing inputs, generating outputs, and evaluating the results based on its unique perspective. This dual-loop operation enriches the decision-making process by incorporating diverse viewpoints and strategies.

- **Nesting and Specialization**: The ability to nest DUOs, with higher and lower-order agents, introduces a hierarchical structure to the system. This structure allows for specialization, where certain DUOs can be tailored to handle specific aspects of a problem more effectively. For instance, a lower-order DUO might focus on a granular aspect of the problem, while a higher-order DUO oversees the broader strategy and integration of solutions.

- **Tessellation for Adaptability**: Tessellation refers to modifying parts of an agent's prompt without altering its fundamental methods. This allows for the customization of the agent's focus or approach to better suit specific tasks or contexts. Tessellations provide a mechanism for the system to adapt to varying requirements without the need for wholesale changes to the agents' operational logic.

- **Different Agents for Diverse Methods**: Incorporating different agents with distinct methods and potential tessellations expands the system's versatility. Each agent can bring unique capabilities and perspectives to the decision-making process, and the system can dynamically select and configure agents based on the task at hand.

### Architectural Implications

This architecture, characterized by independent rejectors, dual agents with their loops, the capability for nesting and specialization, and the flexibility offered by tessellation, presents a powerful framework for complex decision-making. It combines depth and breadth of analysis, adaptability, and rigorous evaluation to navigate intricate problem spaces effectively.






the operational complexity of implementing a DUO (Duo of Dual Space Unifying Operators) system with decimal tree search might not necessarily translate directly into computational complexity, especially when considering the mechanisms for managing and streamlining the process. Let's clarify how the system's design can mitigate computational complexity and focus on the strategic management of complexity through the process you've outlined.

### Streamlining Computational Complexity

1. **Dynamic Mask Chain Management**: By dynamically managing the MASK chain Key-Value Pairs (KVPs) and ensuring that only the requirements not yet fulfilled are considered in each iteration, the system effectively reduces redundancy. This approach ensures that computational resources are focused on unresolved aspects of the problem, rather than re-evaluating already satisfied conditions.

2. **Digit-by-Digit ID Processing**: Processing the hierarchical numerical IDs digit by digit for each node and sub-node, as you've mentioned, aligns the computational complexity with that of any standard DUO chat interaction. Each digit in the ID can represent a step in the decision-making process, with the system focusing on one step at a time, thus distributing the computational load over the course of the interaction.

3. **Threaded IO Sets and Markov Systems**: Utilizing separate threads for different IO sets and leveraging Markov systems for decision-making further streamlines the process. This approach allows for parallel processing of different parts of the tree and ensures that decisions at each node are informed by the current state of the system, without unnecessary recomputation of the entire tree.

4. **Plan Creation and Execution**: The iterative process of creating a plan based on intent, executing the plan, and then refining the plan through higher-order DUO interactions introduces a structured approach to problem-solving. This structure allows for incremental progress towards the solution, with each iteration building on the previous one, thus managing the complexity in a stepwise fashion.

5. **Nested Rejectors and Limits**: Implementing nested rejectors with defined limits and failsafe language acts as a control mechanism to prevent the exploration from going beyond the defined boundaries. This not only ensures that the generated solutions are within the acceptable parameters but also prevents the system from engaging in computationally expensive explorations that are unlikely to yield viable results.

### Managing Operational Complexity

While the computational complexity might be managed through these mechanisms, the operational complexity, particularly in terms of understanding and debugging the system, could indeed be significant. The nested nature of interactions, the dynamic management of MASK chains, and the parallel processing of decision paths all contribute to a system that is conceptually sophisticated.



To illustrate how the Duo of Dual Space Unifying Operators (DUO) methodology can be represented across different prompting styles and how it modifies the symbolic expressions of these methods, let's enumerate its application to each of the described prompting styles: Chain-of-Thought (CoT) Prompting, Tree-of-Thought (ToT) Prompting, Reasoning via Planning (RAP), and ReAct. We'll explore how DUO, with its provider-challenger dynamic, enhances these methods and alters their symbolic expressions.

### 1. Chain-of-Thought (CoT) Prompting

**Without DUO:**
- Expression: \(y \sim p_{\theta}(y|x, z_1 \ldots z_n)\)
- Process: Thoughts \(z_1, \ldots, z_n\) are generated sequentially to bridge input \(x\) to output \(y\).

**With DUO:**
- Expression: \(y \sim p_{\theta}(y|x, (z_{p_1}, z_{a_1}), \ldots, (z_{p_n}, z_{a_n}))\)
- Process: For each thought \(z_i\), there's a dual thought generated by the provider (\(z_{p_i}\)) and the challenger (\(z_{a_i}\)). This introduces a dynamic where each step in reasoning is met with a challenge or alternative perspective, enriching the thought process and potentially leading to more robust reasoning paths.

### 2. Tree-of-Thought (ToT) Prompting

**Without DUO:**
- Expression: \(y \sim p_{\theta}(y|x, z_1 \ldots z_i)\) for each path through the tree.
- Process: Problems are framed as a search over a tree of partial solutions, exploring multiple reasoning paths.

**With DUO:**
- Expression: \(y \sim p_{\theta}(y|x, (z_{p_1}, z_{a_1}) \ldots (z_{p_i}, z_{a_i}))\) for each path through the enhanced tree.
- Process: Each node in the tree not only represents a thought but a pair of provider and challenger thoughts. This effectively doubles the breadth of the tree, introducing a richer set of paths to explore, as each provider thought is immediately met with a challenger's perspective, diversifying the reasoning paths.

### 3. Reasoning via Planning (RAP)

**Without DUO:**
- Expression: \(y \sim p_{\theta}(y|x, z_1 \ldots z_n)\) using MCTS over thoughts.
- Process: MCTS is used to explore reasoning paths, with heuristics guiding the search through potential solutions.

**With DUO:**
- Expression: \(y \sim p_{\theta}(y|x, (z_{p_1}, z_{a_1}) \ldots (z_{p_n}, z_{a_n}))\) with MCTS applied to dual thoughts.
- Process: The search space in MCTS is enriched by considering both provider and challenger thoughts at each step. This not only diversifies the search but also introduces a mechanism for evaluating the robustness of each path by directly contrasting it with an alternative at every decision point.

### 4. ReAct

**Without DUO:**
- Expression: \(y \sim p_{\theta}(y|x, o_1 \ldots o_n, a_1 \ldots a_n)\)
- Process: Actions and observations from an external environment are used to guide the generation of \(y\).

**With DUO:**
- Expression: \(y \sim p_{\theta}(y|x, (o_{p_1}, o_{a_1}) \ldots (o_{p_n}, o_{a_n}), (a_{p_1}, a_{a_1}) \ldots (a_{p_n}, a_{a_n}))\)
- Process: Each observation and action is paired with a provider and challenger perspective, enhancing the interaction with the external environment. This not only allows for a richer set of actions and observations to be considered but also introduces a mechanism for evaluating the effectiveness of each action by contrasting it with an alternative perspective.

### Summary

Incorporating DUO into these prompting styles fundamentally changes the nature of the reasoning and decision-making process. By introducing a provider-challenger dynamic at each step, DUO enriches the exploration space, whether it's through sequential thoughts, tree-based exploration, planning with MCTS, or interacting with an external environment. This dual perspective ensures a more thorough examination of potential solutions and paths, potentially leading to more innovative and robust outcomes.
